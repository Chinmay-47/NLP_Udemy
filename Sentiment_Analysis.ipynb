{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPGDCLCw1TmRu4AKSZmCnQS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chinmay-47/NLP_Udemy/blob/master/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GyvFcivyV_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "negative_reviews = BeautifulSoup(open('negative.review').read(),features= \"html5lib\")\n",
        "negative_reviews = negative_reviews.findAll('review_text')\n",
        "positive_reviews = BeautifulSoup(open('positive.review').read(),features= \"html5lib\")\n",
        "positive_reviews = positive_reviews.findAll('review_text')\n",
        "unlabelled_reviews = BeautifulSoup(open('unlabeled.review').read(),features= \"html5lib\")\n",
        "unlabelled_reviews = unlabelled_reviews.findAll('review_text')"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT5Cv1L51pf7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "aff6e16a-dd8f-4edd-853f-3697c9ed155d"
      },
      "source": [
        "#Clean Up to prepare for training\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "stopwords = set(w.rstrip() for w in open('stopwords.txt'))\n",
        "\n",
        "def tokenizer(a):\n",
        "    a = a.lower()\n",
        "    tokens = nltk.tokenize.word_tokenize(a)\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    tokens = [token for token in tokens if len(token)>2]\n",
        "    tokens = [wordnet_lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return tokens\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fByhclF3HHJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bcba765-5e6a-44f2-9000-917e497327ec"
      },
      "source": [
        "unique_words = {}\n",
        "index = 0\n",
        "positive_tokenized = []\n",
        "negative_tokenized = []\n",
        "original_reviews = []\n",
        "\n",
        "for r in positive_reviews:\n",
        "    original_reviews.append(r.text)\n",
        "    tokens = tokenizer(r.text)\n",
        "    positive_tokenized.append(tokens)\n",
        "    for token in tokens:\n",
        "        if token not in unique_words:\n",
        "            unique_words[token] = index\n",
        "            index+=1\n",
        "\n",
        "for n in negative_reviews:\n",
        "    original_reviews.append(n.text)\n",
        "    tokens = tokenizer(n.text)\n",
        "    negative_tokenized.append(tokens)\n",
        "    for token in tokens:\n",
        "        if token not in unique_words:\n",
        "            unique_words[token] = index\n",
        "            index+=1\n",
        "\n",
        "print(\"len(unique_words):\", len(unique_words))\n",
        "#key = unique tokens and value=index"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(unique_words): 11106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4fxmjMg5i8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d4e66240-fd04-4132-c558-667ed231b7b9"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def tokens_to_vector(tokens,label):\n",
        "    x = np.zeros(len(unique_words)+1)\n",
        "    for t in tokens:\n",
        "        i = unique_words[t]\n",
        "        x[i] +=1\n",
        "    x = x/x.sum()\n",
        "    x[-1] = label\n",
        "    return x\n",
        "\n",
        "N = len(positive_tokenized) + len(negative_tokenized)\n",
        "\n",
        "data = np.zeros((N,len(unique_words)+1))\n",
        "i= 0\n",
        "\n",
        "for token in positive_tokenized:\n",
        "    xy = tokens_to_vector(token,1)\n",
        "    data[i,:] = xy\n",
        "    i+=1\n",
        "\n",
        "for token in negative_tokenized:\n",
        "    xy = tokens_to_vector(token,0)\n",
        "    data[i,:] = xy\n",
        "    i+=1\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "data, original_reviews = shuffle(data,original_reviews)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xtrain, XTest, Ytrain, Ytest = train_test_split(data[:,:-1],data[:,-1],test_size = 0.33,shuffle= True)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = LogisticRegression()\n",
        "model1 = AdaBoostClassifier()\n",
        "model2 = RandomForestClassifier()\n",
        "\n",
        "model.fit(Xtrain,Ytrain)\n",
        "model1.fit(Xtrain,Ytrain)\n",
        "model2.fit(Xtrain,Ytrain)\n",
        "\n",
        "print(\"Training accuracy of model : \", model.score(Xtrain,Ytrain))\n",
        "print(\"Test accuracy of model : \", model.score(XTest,Ytest))\n",
        "print(\"Training accuracy of model1 : \", model1.score(Xtrain,Ytrain))\n",
        "print(\"Test accuracy of model1 : \", model1.score(XTest,Ytest))\n",
        "print(\"Training accuracy of model1 : \", model2.score(Xtrain,Ytrain))\n",
        "print(\"Test accuracy of model1 : \", model2.score(XTest,Ytest))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy of model :  0.7947761194029851\n",
            "Test accuracy of model :  0.7303030303030303\n",
            "Training accuracy of model1 :  0.841044776119403\n",
            "Test accuracy of model1 :  0.7151515151515152\n",
            "Training accuracy of model1 :  1.0\n",
            "Test accuracy of model1 :  0.793939393939394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgQWxa0oRGbF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "9176d2e6-5f1d-465d-9a4c-1e7ce3c5f49e"
      },
      "source": [
        "# let's look at the weights for each word\n",
        "# try it with different threshold values!\n",
        "from future.utils import iteritems\n",
        "threshold = 0.5\n",
        "for word, index in iteritems(unique_words):\n",
        "    weight = model.coef_[0][index]\n",
        "    if weight > threshold or weight < -threshold:\n",
        "        print(word, weight)\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bad -0.6603978121335308\n",
            "day -0.5149190071734071\n",
            "'ve 0.5365274108819938\n",
            "sound 0.7261732691078957\n",
            "lot 0.5874070608735378\n",
            "n't -1.6758082610989142\n",
            "easy 1.4480397975037347\n",
            "quality 1.0396383800022515\n",
            "card -0.5425538062698667\n",
            "item -0.6649913255729275\n",
            "perfect 0.6099835606159258\n",
            "fast 0.6810597999933578\n",
            "price 2.2046421736354995\n",
            "money -0.6436933539717562\n",
            "memory 0.5618716697414786\n",
            "picture 0.5214866693483268\n",
            "buy -0.6535091808293393\n",
            "happy 0.5082706768739143\n",
            "pretty 0.572200993659159\n",
            "highly 0.7575087461447255\n",
            "support -0.7163096321596831\n",
            "little 0.7912586956264775\n",
            "returned -0.5453165603473059\n",
            "excellent 0.881130558524569\n",
            "love 0.8198512416887568\n",
            "week -0.618128239111465\n",
            "size 0.5229419245550312\n",
            "using 0.5576442928495882\n",
            "ipod -0.592987027282843\n",
            "poor -0.684190870068703\n",
            "then -0.9504226025513846\n",
            "tried -0.6098365162978384\n",
            "try -0.6048710295322687\n",
            "photo 0.5238503479523994\n",
            "speaker 1.0178414393568573\n",
            "broken -0.531591179209445\n",
            "paper 0.599725154989537\n",
            "return -1.0227898979035286\n",
            "waste -0.6628778237089521\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYz8FWTF_pwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check misclassified examples\n",
        "preds = model.predict(data[:,:-1])\n",
        "P = model.predict_proba(data[:,:-1])[:,1] # p(y = 1 | x)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wahAz98fQgw_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "e3e07201-6e48-4bb5-9a4a-a299e7e2452c"
      },
      "source": [
        "# since there are many, just print the \"most\" wrong samples\n",
        "minP_whenYis1 = 1\n",
        "maxP_whenYis0 = 0\n",
        "wrong_positive_review = None\n",
        "wrong_negative_review = None\n",
        "wrong_positive_prediction = None\n",
        "wrong_negative_prediction = None\n",
        "for i in range(N):\n",
        "    p = P[i]\n",
        "    y = data[:,-1][i]\n",
        "    if y == 1 and p < 0.5:\n",
        "        if p < minP_whenYis1:\n",
        "            wrong_positive_review = original_reviews[i]\n",
        "            wrong_positive_prediction = preds[i]\n",
        "            minP_whenYis1 = p\n",
        "    elif y == 0 and p > 0.5:\n",
        "        if p > maxP_whenYis0:\n",
        "            wrong_negative_review = original_reviews[i]\n",
        "            wrong_negative_prediction = preds[i]\n",
        "            maxP_whenYis0 = p\n",
        "\n",
        "print(\"Most wrong positive review (prob = %s, pred = %s):\" % (minP_whenYis1, wrong_positive_prediction))\n",
        "print(wrong_positive_review)\n",
        "print(\"Most wrong negative review (prob = %s, pred = %s):\" % (maxP_whenYis0, wrong_negative_prediction))\n",
        "print(wrong_negative_review)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most wrong positive review (prob = 0.42810195908084964, pred = 0.0):\n",
            "\n",
            "the product arrive to me in very good condition, will recommend this product to anyone who needs blank cd\n",
            "\n",
            "Most wrong negative review (prob = 0.5890300620915938, pred = 1.0):\n",
            "\n",
            "Like the forward/back buttons but they are located too far back on the body for comfort.  Like the scroll wheel and side-to-side scroll ability.  Pointer flickers a lot sometimes and often disappears over certain buttons.  Logitech website gives no help.\n",
            "Comes with an installation CD for a Logitech MX320 !!!  Be prepared for a 50MB download to install the MX400.  Almost makes Microsot look good\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}